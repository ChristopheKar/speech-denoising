{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38175b8-0e2f-449d-aedd-b248005272b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import display\n",
    "from dataset import NoisyLibriSpeechDataset, utils\n",
    "from models import FCAE, CDAE, UNet\n",
    "from train import set_device, train, evaluate\n",
    "\n",
    "# Set compute device\n",
    "device = set_device(verbose=True)\n",
    "\n",
    "# Data params\n",
    "srate = 16000\n",
    "data_root = 'data/noised_synth_babble'\n",
    "libri_root = 'data/LibriSpeech/dev-clean'\n",
    "seed = 11\n",
    "batch_size=8\n",
    "\n",
    "N = 10\n",
    "test_size = .10\n",
    "conv = True\n",
    "\n",
    "# Create dataset splits\n",
    "train_idxs, val_idxs, test_idxs = utils.get_data_split_idxs(\n",
    "    N, test_size=test_size, seed=seed)\n",
    "\n",
    "# Load training data\n",
    "data_train = NoisyLibriSpeechDataset(\n",
    "    data_root=data_root, libri_root=libri_root,\n",
    "    include_idxs=train_idxs, test=False,\n",
    "    conv=conv, seed=seed)\n",
    "train_dl = DataLoader(\n",
    "    data_train, batch_size=batch_size,\n",
    "    num_workers=0, pin_memory=False)\n",
    "\n",
    "# Load validation data\n",
    "data_val = NoisyLibriSpeechDataset(\n",
    "    data_root=data_root, libri_root=libri_root,\n",
    "    include_idxs=val_idxs, test=False,\n",
    "    conv=conv, seed=seed)\n",
    "val_dl = DataLoader(\n",
    "    data_val, batch_size=batch_size,\n",
    "    num_workers=0, pin_memory=False)\n",
    "\n",
    "# Load testing data\n",
    "data_test = NoisyLibriSpeechDataset(\n",
    "    data_root=data_root, libri_root=libri_root,\n",
    "    include_idxs=test_idxs, test=True,\n",
    "    conv=conv, seed=seed)\n",
    "\n",
    "display.show_split_sizes((data_train, data_val, data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c0208-efb7-43be-ad65-03e70b29f7d8",
   "metadata": {},
   "source": [
    "## Fully-Connected Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c0f7c-6ec0-403e-a987-38bdc3ff0f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "loss = nn.BCELoss()\n",
    "epochs = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create model and send to device\n",
    "model = FCAE(\n",
    "    data_train.target_shape,\n",
    "    n_layers=4,\n",
    "    z_dim=8).to(device)\n",
    "\n",
    "# Train model\n",
    "model, hist = train(\n",
    "    device, model,\n",
    "    train_dl, val_dl,\n",
    "    epochs=epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    criterion=loss)\n",
    "\n",
    "# Plot Losses\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax = display.plot_losses(ax, hist, 'MSE')\n",
    "fig.show()\n",
    "\n",
    "# Evaluate Model\n",
    "fig, axes = evaluate(device, model, data_test)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbfc7c3-c693-4589-a1e7-176892f3bda3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b9a38-ea0b-4766-9883-c8331433d1ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "epochs = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = CDAE(\n",
    "    n_layers=4, \n",
    "    z_dim=8,\n",
    "    in_channels=1,\n",
    "    batch_norm=True).to(device)\n",
    "\n",
    "model, hist = train(\n",
    "    device, model,\n",
    "    train_dl, val_dl,\n",
    "    epochs=epochs, \n",
    "    learning_rate=learning_rate,\n",
    "    criterion=loss)\n",
    "\n",
    "# Plot Losses\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax = display.plot_losses(ax, hist, 'MSE')\n",
    "fig.show()\n",
    "\n",
    "# Evaluate Model\n",
    "fig, axes = evaluate(device, model, data_test)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4126a2b-4a3b-426a-a57f-60b3bde17774",
   "metadata": {},
   "source": [
    "## U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329763b8-56c7-4eaf-a28f-82b8f8db0770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "epochs = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = UNet(up_mode='upsample', in_channels=1, n_classes=1).to(device)\n",
    "model, hist = train(\n",
    "    device, model,\n",
    "    train_dl, val_dl,\n",
    "    epochs=epochs, \n",
    "    learning_rate=learning_rate,\n",
    "    criterion=loss)\n",
    "\n",
    "# Plot Losses\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax = plot_losses(ax, hist, 'MSE')\n",
    "fig.show()\n",
    "\n",
    "# Evaluate Model\n",
    "fig, axes = evaluate(device, model, data_test)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
